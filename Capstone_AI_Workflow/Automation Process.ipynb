{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case study objectives\n",
    "\n",
    "1. Gather all relevant data from the sources \n",
    "2. Implement several checks for quality assurance \n",
    "3. Automating of the ingestion pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gathering the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the libraries as needed\n",
    "import os\n",
    "from datetime import datetime\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "\n",
    "## specify the directory you saved the data in\n",
    "# data_dir = os.path.join(\"..\",\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CUSTOMER', 'INVOICE', 'INVOICE_ITEM', 'COUNTRY']\n"
     ]
    }
   ],
   "source": [
    "## connect to the database\n",
    "rdb_path = os.path.join(\".\",\"Data/aavail-customers.db\")\n",
    "conn = sqlite3.connect(rdb_path)\n",
    "\n",
    "## take a look of the tables when connecting the database\n",
    "tables = [t[0] for t in conn.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")]\n",
    "print(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>last_name</th>\n",
       "      <th>first_name</th>\n",
       "      <th>DOB</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>country</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Todd</td>\n",
       "      <td>Kasen</td>\n",
       "      <td>07/30/98</td>\n",
       "      <td>Rock Hill</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>united_states</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Garza</td>\n",
       "      <td>Ensley</td>\n",
       "      <td>04/12/89</td>\n",
       "      <td>singapore</td>\n",
       "      <td>None</td>\n",
       "      <td>singapore</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Carey</td>\n",
       "      <td>Lillian</td>\n",
       "      <td>09/12/97</td>\n",
       "      <td>Auburn</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>united_states</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Christensen</td>\n",
       "      <td>Beau</td>\n",
       "      <td>01/28/99</td>\n",
       "      <td>Hempstead</td>\n",
       "      <td>New York</td>\n",
       "      <td>united_states</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gibson</td>\n",
       "      <td>Ernesto</td>\n",
       "      <td>03/23/98</td>\n",
       "      <td>singapore</td>\n",
       "      <td>None</td>\n",
       "      <td>singapore</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id    last_name first_name       DOB       city           state  \\\n",
       "0            1         Todd      Kasen  07/30/98  Rock Hill  South Carolina   \n",
       "1            2        Garza     Ensley  04/12/89  singapore            None   \n",
       "2            3        Carey    Lillian  09/12/97     Auburn         Alabama   \n",
       "3            4  Christensen       Beau  01/28/99  Hempstead        New York   \n",
       "4            5       Gibson    Ernesto  03/23/98  singapore            None   \n",
       "\n",
       "         country gender  \n",
       "0  united_states      m  \n",
       "1      singapore      f  \n",
       "2  united_states      f  \n",
       "3  united_states      m  \n",
       "4      singapore      m  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write a sql query to retrieve the needed data\n",
    "query = \"\"\"\n",
    "SELECT cu.customer_id, cu.last_name, cu.first_name, cu.DOB,\n",
    "       cu.city, cu.state, co.country_name, cu.gender\n",
    "FROM CUSTOMER cu\n",
    "INNER JOIN COUNTRY co\n",
    "ON cu.country_id = co.country_id;\n",
    "\"\"\"\n",
    "\n",
    "_data = [d for d in conn.execute(query)]\n",
    "columns = [\"customer_id\",\"last_name\",\"first_name\",\"DOB\",\"city\",\"state\",\"country\",\"gender\"]\n",
    "df_db = pd.DataFrame(_data,columns=columns)\n",
    "##\n",
    "df_db.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's extract the relevant data from the CSV file as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18859, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>stream_id</th>\n",
       "      <th>date</th>\n",
       "      <th>invoice_item_id</th>\n",
       "      <th>subscription_stopped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1420.0</td>\n",
       "      <td>2018-10-21</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1343.0</td>\n",
       "      <td>2018-10-23</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1756.0</td>\n",
       "      <td>2018-11-05</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1250.0</td>\n",
       "      <td>2018-11-06</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1324.0</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  stream_id        date  invoice_item_id  subscription_stopped\n",
       "0            1     1420.0  2018-10-21              2.0                     0\n",
       "1            1     1343.0  2018-10-23              2.0                     0\n",
       "2            1     1756.0  2018-11-05              2.0                     0\n",
       "3            1     1250.0  2018-11-06              2.0                     0\n",
       "4            1     1324.0  2018-11-12              2.0                     0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## retrieve the relevant data from a csv file\n",
    "df_streams = pd.read_csv(os.path.join(\".\",r\"Data/aavail-streams.csv\"))\n",
    "print(df_streams.shape)\n",
    "df_streams.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## form a churn table as needed (from the csv file above)\n",
    "customer_ids = df_streams['customer_id'].values\n",
    "\n",
    "#unique_ids = np.unique(df_streams['customer_id'].values)\n",
    "unique_ids = df_streams.customer_id.unique()\n",
    "\n",
    "streams = df_streams['subscription_stopped'].values\n",
    "has_churned = [0 if streams[customer_ids==uid].max() > 0 else 1 for uid in unique_ids]\n",
    "df_churn = pd.DataFrame({\"customer_id\": unique_ids,\"is_subscriber\": has_churned})\n",
    "\n",
    "#df_churn.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checks for quality assurance\n",
    "\n",
    "Sometimes it is known in advance which types of data integrity issues to expect, but other times it is during the Exploratory Data Analysis (EDA) process that these issues are identified.  After extracting data it is important to include checks for quality assurance even on the first pass through the AI workflow. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaning Summary\n",
      "-----------------------------------\n",
      "Removed 7 duplicate rows\n",
      "Removed 1164 missing stream ids\n",
      "\n",
      "Missing Value Summary\n",
      "-----------------------------------\n",
      "\n",
      "df_db\n",
      "---------------\n",
      "customer_id      0\n",
      "last_name        0\n",
      "first_name       0\n",
      "DOB              0\n",
      "city             0\n",
      "state          300\n",
      "country          0\n",
      "gender           0\n",
      "dtype: int64\n",
      "\n",
      "df_streams\n",
      "---------------\n",
      "customer_id             0\n",
      "stream_id               0\n",
      "date                    0\n",
      "invoice_item_id         0\n",
      "subscription_stopped    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## check & display the results\n",
    "print(\"\\nCleaning Summary\\n{}\".format(\"-\"*35))\n",
    "duplicate_rows = df_db.duplicated()\n",
    "\n",
    "if True in duplicate_rows:\n",
    "    df_db = df_db[~duplicate_rows]\n",
    "print(\"Removed {} duplicate rows\".format(np.where(duplicate_rows==True)[0].size))\n",
    "\n",
    "missing_stream_ids = np.isnan(df_streams['stream_id'])    \n",
    "if True in missing_stream_ids:\n",
    "    df_streams = df_streams[~missing_stream_ids]\n",
    "    \n",
    "    \n",
    "print(\"Removed {} missing stream ids\".format(np.where(missing_stream_ids==True)[0].size))\n",
    "\n",
    "print(\"\\nMissing Value Summary\\n{}\".format(\"-\"*35))\n",
    "print(\"\\ndf_db\\n{}\".format(\"-\"*15))\n",
    "print(df_db.isnull().sum(axis = 0))\n",
    "print(\"\\ndf_streams\\n{}\".format(\"-\"*15))\n",
    "print(df_streams.isnull().sum(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>invoice_item_id</th>\n",
       "      <th>subscription_stopped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  invoice_item_id  subscription_stopped\n",
       "0            1              2.0                    23\n",
       "1            2              3.0                    12\n",
       "2            3              2.0                    22\n",
       "3            4              1.0                    19"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## form a new stream table as needed\n",
    "new_stream = df_streams[['customer_id','invoice_item_id','subscription_stopped']]\\\n",
    "            .groupby(['customer_id','invoice_item_id'],as_index=False).count()\n",
    "new_stream.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>invoice_item_id</th>\n",
       "      <th>subscriber_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>aavail_basic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>aavail_premium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>aavail_unlimited</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   invoice_item_id   subscriber_type\n",
       "0                1      aavail_basic\n",
       "1                2    aavail_premium\n",
       "2                3  aavail_unlimited"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## retrieve data from \"invoice item\" table as needed\n",
    "invo_item = \"\"\"\n",
    "SELECT invoice_item_id, invoice_item as subscriber_type\n",
    "FROM INVOICE_ITEM;\n",
    "\"\"\"\n",
    "\n",
    "_dat = [d for d in conn.execute(invo_item)]\n",
    "columns = [\"invoice_item_id\",\"subscriber_type\"]\n",
    "sub_type = pd.DataFrame(_dat,columns=columns)\n",
    "\n",
    "sub_type.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's combine the data into a single data structure and using the JOIN method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>state</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>is_subscriber</th>\n",
       "      <th>customer_name</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>subscriber_type</th>\n",
       "      <th>num_streams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>united_states</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Kasen Todd</td>\n",
       "      <td>21</td>\n",
       "      <td>m</td>\n",
       "      <td>aavail_premium</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>singapore</td>\n",
       "      <td>None</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Ensley Garza</td>\n",
       "      <td>30</td>\n",
       "      <td>f</td>\n",
       "      <td>aavail_unlimited</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>united_states</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Lillian Carey</td>\n",
       "      <td>22</td>\n",
       "      <td>f</td>\n",
       "      <td>aavail_premium</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>united_states</td>\n",
       "      <td>New York</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Beau Christensen</td>\n",
       "      <td>20</td>\n",
       "      <td>m</td>\n",
       "      <td>aavail_basic</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>singapore</td>\n",
       "      <td>None</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Ernesto Gibson</td>\n",
       "      <td>21</td>\n",
       "      <td>m</td>\n",
       "      <td>aavail_premium</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         country           state  customer_id  is_subscriber  \\\n",
       "0  united_states  South Carolina            1              1   \n",
       "1      singapore            None            2              0   \n",
       "2  united_states         Alabama            3              0   \n",
       "3  united_states        New York            4              1   \n",
       "4      singapore            None            5              1   \n",
       "\n",
       "      customer_name  age gender   subscriber_type  num_streams  \n",
       "0        Kasen Todd   21      m    aavail_premium           23  \n",
       "1      Ensley Garza   30      f  aavail_unlimited           12  \n",
       "2     Lillian Carey   22      f    aavail_premium           22  \n",
       "3  Beau Christensen   20      m      aavail_basic           19  \n",
       "4    Ernesto Gibson   21      m    aavail_premium           23  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## now let's join the four tables together (form a final dataset)\n",
    "\n",
    "new_dat1 = pd.merge(df_churn,df_db,how=\"inner\",left_on='customer_id',right_on='customer_id')\n",
    "new_dat2 = pd.merge(new_dat1,new_stream,how=\"inner\",left_on='customer_id',right_on='customer_id')\n",
    "df_new = pd.merge(new_dat2,sub_type,how=\"inner\",left_on=\"invoice_item_id\",right_on=\"invoice_item_id\")\n",
    "# df_new.head()\n",
    "\n",
    "## finalizing the dataset:\n",
    "## convert age to days\n",
    "df_new['age'] = np.datetime64('today') - pd.to_datetime(df_new['DOB'])\n",
    "## convert to age(int) \n",
    "df_new['age'] = [a.astype('timedelta64[Y]').astype(int) for a in df_new['age'].values]\n",
    "\n",
    "df_new['customer_name'] = df_new['first_name'] + \" \" + df_new['last_name']\n",
    "df_new['num_streams'] = df_new['subscription_stopped']\n",
    "new_col = [\"country\",\"state\",\"customer_id\",\"is_subscriber\",\"customer_name\",\"age\",\"gender\",\"subscriber_type\",\"num_streams\"]\n",
    "dat = df_new[new_col]\n",
    "dat = dat.sort_values(by=['customer_id'])\n",
    "\n",
    "## reset index\n",
    "dat = dat.reset_index()\n",
    "dat.drop('index', inplace=True, axis=1)\n",
    "\n",
    "## display\n",
    "dat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automating the process\n",
    "\n",
    "1. Save the cleaned, combined data as a CSV file.\n",
    "2. Create a function or class that performs all of the steps given a database file and a streams CSV file.\n",
    "3. Run the function in batches and write a check to ensure the same result.\n",
    "\n",
    "There would be some logic involved in the automation process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code to split the streams csv into batches\n",
    "df_all = pd.read_csv(os.path.join(\".\",\"data/aavail-streams.csv\"))\n",
    "half = int(round(df_all.shape[0] * 0.5))\n",
    "df_part1 = df_all[:half]\n",
    "df_part2 = df_all[half:]\n",
    "df_part1.to_csv(os.path.join(\".\",\"data/aavail-streams-1.csv\"),index=False)\n",
    "df_part2.to_csv(os.path.join(\".\",\"data/aavail-streams-2.csv\"),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now automating the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting aavail-data-ingestor.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile aavail-data-ingestor.py\n",
    "#!/usr/bin/env python\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import getopt\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "\n",
    "# DATA_DIR = os.path.join(\"..\",\"data\")\n",
    "\n",
    "def connect_db(file_path):\n",
    "    \"\"\"\n",
    "    function to connection to aavail database\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(file_path)\n",
    "        print(\"...successfully connected to db\")\n",
    "    except Error as e:\n",
    "        print(\"...unsuccessful connection\",e)\n",
    "    \n",
    "    return(conn)\n",
    "\n",
    "## passing the parameter \"conn\" from last output\n",
    "def ingest_db_data(conn):\n",
    "    \"\"\"\n",
    "    load and clean the db data\n",
    "    \"\"\"\n",
    "    \n",
    "    query = \"\"\"\n",
    "            SELECT cu.customer_id, cu.last_name, cu.first_name, cu.DOB,\n",
    "            cu.city, cu.state, co.country_name, cu.gender\n",
    "            FROM CUSTOMER cu\n",
    "            INNER JOIN COUNTRY co\n",
    "            ON cu.country_id = co.country_id;\n",
    "            \"\"\"\n",
    "    _data = [d for d in conn.execute(query)]\n",
    "    columns = [\"customer_id\",\"last_name\",\"first_name\",\"DOB\",\"city\",\"state\",\"country\",\"gender\"]\n",
    "    df_db = pd.DataFrame(_data,columns=columns)\n",
    "    ## the duplicated rows:\n",
    "    duplicate_rows = df_db.duplicated()\n",
    "    if True in duplicate_rows:\n",
    "        df_db = df_db[~duplicate_rows]\n",
    "        df_db.reset_index()\n",
    "    print(\"... removed {} duplicate rows in db data\".format(np.where(duplicate_rows==True)[0].size))\n",
    "    return(df_db)\n",
    "\n",
    "## we'll know the file path\n",
    "def ingest_stream_data(file_path):\n",
    "    \"\"\"\n",
    "    load and clean the stream data\n",
    "    \"\"\"\n",
    "    \n",
    "    df_streams = pd.read_csv(file_path)\n",
    "    \n",
    "    ## ingest the churn data:\n",
    "    customer_ids = df_streams['customer_id'].values\n",
    "    # unique_ids = np.unique(df_streams['customer_id'].values)\n",
    "    unique_ids = df_streams.customer_id.unique()\n",
    "    \n",
    "    streams = df_streams['subscription_stopped'].values\n",
    "    has_churned = [0 if streams[customer_ids==uid].max() > 0 else 1 for uid in unique_ids]\n",
    "    df_churn = pd.DataFrame({\"customer_id\": unique_ids,\"is_subscriber\": has_churned})\n",
    "    \n",
    "    missing_stream_ids = np.isnan(df_streams['stream_id'])    \n",
    "    if True in missing_stream_ids:\n",
    "        df_streams = df_streams[~missing_stream_ids]\n",
    "        df_streams.reset_index()\n",
    "    print(\"... removed {} missing stream ids\".format(np.where(missing_stream_ids==True)[0].size))\n",
    "    \n",
    "    return(df_streams,df_churn)\n",
    "\n",
    "## passing the 3 parameters from last outputs\n",
    "def process_dataframes(df_streams,df_db,df_churn):\n",
    "    \"\"\"\n",
    "    add data to target csv\n",
    "    \"\"\"\n",
    "\n",
    "    ## we form a new stream table\n",
    "    new_stream = df_streams[['customer_id','invoice_item_id','subscription_stopped']]\\\n",
    "            .groupby(['customer_id','invoice_item_id'],as_index=False).count()\n",
    "    # new_stream.head(4)\n",
    "\n",
    "    ## ensure we are working with correctly ordered customer_ids df_db\n",
    "    if not np.array_equal(df_churn['customer_id'],df_db['customer_id']):\n",
    "        raise Exception(\"indexes are out of order or unmatched---needs to fix\")\n",
    "\n",
    "    ## retrieve data from \"invoice item\" table\n",
    "    invo_item = \"\"\"\n",
    "    SELECT invoice_item_id, invoice_item as subscriber_type\n",
    "    FROM INVOICE_ITEM;\n",
    "    \"\"\"\n",
    "\n",
    "    _dat = [d for d in conn.execute(invo_item)]\n",
    "    columns = [\"invoice_item_id\",\"subscriber_type\"]\n",
    "    sub_type = pd.DataFrame(_dat,columns=columns)\n",
    "    # sub_type.head(3)\n",
    "\n",
    "    ## now let's join the four tables together (form a dataset)\n",
    "    new_dat1 = pd.merge(df_churn,df_db,how=\"inner\",left_on='customer_id',right_on='customer_id')\n",
    "    new_dat2 = pd.merge(new_dat1,new_stream,how=\"inner\",left_on='customer_id',right_on='customer_id')\n",
    "    df_new = pd.merge(new_dat2,sub_type,how=\"inner\",left_on=\"invoice_item_id\",right_on=\"invoice_item_id\")\n",
    "    # df_new.head()\n",
    "\n",
    "    ## finalizing the dataset:\n",
    "    ## convert age to days\n",
    "    df_new['age'] = np.datetime64('today') - pd.to_datetime(df_new['DOB'])\n",
    "    ## convert to age(int) \n",
    "    df_new['age'] = [a.astype('timedelta64[Y]').astype(int) for a in df_new['age'].values]\n",
    "\n",
    "    df_new['customer_name'] = df_new['first_name'] + \" \" + df_new['last_name']\n",
    "    df_new['num_streams'] = df_new['subscription_stopped']\n",
    "    new_col = [\"country\",\"state\",\"customer_id\",\"is_subscriber\",\"customer_name\",\"age\",\"gender\",\"subscriber_type\",\"num_streams\"]\n",
    "    dat = df_new[new_col]\n",
    "    dat = dat.sort_values(by=['customer_id'])\n",
    "\n",
    "    ## reset index\n",
    "    dat = dat.reset_index()\n",
    "    dat.drop('index', inplace=True, axis=1)\n",
    "\n",
    "    ## display\n",
    "    # dat.head()\n",
    "    return(dat)\n",
    "\n",
    "## upate the target file    \n",
    "def update_target(target_file,dat,overwrite=False):\n",
    "    \"\"\"\n",
    "    update line by line in case data are large\n",
    "    \"\"\"\n",
    "\n",
    "    if overwrite or not os.path.exists(target_file):\n",
    "        dat.to_csv(target_file,index=False)   \n",
    "    else:\n",
    "        df_target = pd.read_csv(target_file)\n",
    "        df_target.to_csv(target_file, mode='a',index=False)\n",
    "        \n",
    "        \n",
    "         \n",
    "if __name__ == \"__main__\":\n",
    "  \n",
    "    ## collect args\n",
    "    arg_string = \"%s -d db_filepath -s streams_filepath\"%sys.argv[0]\n",
    "    try:\n",
    "        optlist, args = getopt.getopt(sys.argv[1:],'d:s:')\n",
    "    except getopt.GetoptError:\n",
    "        print(getopt.GetoptError)\n",
    "        raise Exception(arg_string)\n",
    "\n",
    "    ## handle args\n",
    "    streams_file = None\n",
    "    db_file = None\n",
    "    for o, a in optlist:\n",
    "        if o == '-d':\n",
    "            db_file = a\n",
    "        if o == '-s':\n",
    "            streams_file = a\n",
    "    streams_file = os.path.join(\".\",streams_file)\n",
    "    db_file = os.path.join(\".\",db_file)\n",
    "    target_file = os.path.join(\".\",\"aavail-target.csv\")\n",
    "    \n",
    "    \n",
    "    ## make the connection to the database\n",
    "    conn = connect_db(db_file)\n",
    "\n",
    "    ## ingest data base data\n",
    "    df_db = ingest_db_data(conn)\n",
    "    df_streams, df_churn = ingest_stream_data(streams_file)\n",
    "    df_clean = process_dataframes(df_streams, df_db, df_churn)\n",
    "    \n",
    "    ## write\n",
    "    update_target(target_file,dat,overwrite=False)\n",
    "    ##\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the script created from the commandline directly or from within this notebook using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...successfully connected to db\n",
      "... removed 7 duplicate rows in db data\n",
      "... removed 1164 missing stream ids\n",
      "   customer_id  is_subscriber  ...   subscriber_type  num_streams\n",
      "0            1              1  ...    aavail_premium           23\n",
      "1            2              0  ...  aavail_unlimited           12\n",
      "2            3              0  ...    aavail_premium           22\n",
      "3            4              1  ...      aavail_basic           19\n",
      "4            5              1  ...    aavail_premium           23\n",
      "\n",
      "[5 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "!python aavail-data-ingestor.py aavail-customers.db aavail-streams-1.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the script once for each batch and then load both the original and batch versions back into the notebook to check if they are the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...successfully connected to db\n",
      "... removed 7 duplicate rows in db data\n",
      "... removed 1164 missing stream ids\n",
      "done\n",
      "    1001 ../data/aavail-target.csv\n"
     ]
    }
   ],
   "source": [
    "## \n",
    "!rm ../data/aavail-target.csv\n",
    "!python aavail-data-ingestor.py -d aavail-customers.db -s aavail-streams.csv\n",
    "!wc -l ../data/aavail-target.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...successfully connected to db\n",
      "... removed 7 duplicate rows in db data\n",
      "... removed 577 missing stream ids\n",
      "done\n",
      "     507 ../data/aavail-target.csv\n",
      "...successfully connected to db\n",
      "... removed 7 duplicate rows in db data\n",
      "... removed 587 missing stream ids\n",
      "done\n",
      "    1014 ../data/aavail-target.csv\n"
     ]
    }
   ],
   "source": [
    "!rm ../data/aavail-target.csv\n",
    "!python aavail-data-ingestor.py -d aavail-customers.db -s aavail-streams-1.csv\n",
    "!wc -l ../data/aavail-target.csv\n",
    "!python aavail-data-ingestor.py -d aavail-customers.db -s aavail-streams-2.csv\n",
    "!wc -l ../data/aavail-target.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
